SLIDE 1

Welcome to my PhD thesis Defense, and thanks very much to Dr. SentÃ­s, Dr. Holmes and Dr. Zambrini for being here, it is a big pleasure that you accepted to be part of the tribunal.

Before beggining I want to mention two technical details which are important.

The first one is that you have access to the slides by scanning thsi QR code, and also to the digital version of the PhD thesis, links are in the github repository.

The second one is that this thesis touches quite a variety of topics in quantum info and machine learning, and the overall consequence of this is my presentation will extend a bit longer than the usual, for around 1.15 mins.


SLIDE 2

So this thesis is a theoretical work that however deals with problems of great relevane in several near/mid term quantum technologies. In particular, each of the main lines of my thesis is closely related to quantum communications, quantum computing and quantum sensing.


SLIDE 3

In quantum communications, and in particular long-distance quantum communications, we use light as an information career in order to communicate between two parties, for example ground earth and a satellite.

Why do we use light? Well, we use it because photons move fast, and they ussually intereact very little with the environment.

However, for signals whose intensity is weak enough, quantum effects (and in particular distinguishability effects) become relevant. Thus, the question of how to best measure the quantum information raises. While in many cases we can provide a theoretical answer for such a question, implementing the optimal measurement is potentially forbidden with current technologies, and another question raises which is how to implement such measurement in the lab.

Moreover, the presence of noisy channels might alter the original signal, and this channels are often hard to model in practice. So the necesisty to develop tools to deal with unknown sources of noise in long-distance quantum communications, and thus to "calibrate" the quatnum measurement to the specific setting at hand, is also present.


SLIDE 4

On the other hand, we have the so called Noisy Intermmedaite-Scale quantum devices, which are very small and very noisy versions of a quantum computer and need to be tailored in such a way to perform an specific task. Despite the incredible amount of noise and limitations that we currently need to deal when working with such devices, it has recently been achieved an experimental quantum advantage for boson sampling problem. However, among the many problems that NISQ devices present nowadays, we still lack techniques for how to tailor the NISQ hardware (that means, how to design a quantum circuit) for a given specific task.


SLIDE 5

Finally, despite all the noise that is injected in NISQ devices for quantum computing purposes, we do have a precise experimental control of quantum systems in the lab. The same reason that makes quantum systems so fragile and hard to handle also makes them highly sensitive to external interactions with their environment. Here, we will focus on a quantum system that is being continuously-monitored. This leads to a measurement signal, and we will develop tools for better process this classical data.


SLIDE 6

In each of the problems introduced before, namely measurement calibration for long-distance quantum communication, quantum crcuit design in NISQ applications and data processing for continuously-monitored quantum systems, we can readily identify that a decision needs to be taken by us, scientists, in order to better make use of such technologies (and perhaphs importantly, to explore quantum nature).

In this thesis we use each of these paradigmatic problems as a framework for us - human scientists - to interact with artificially-intelligent agents.

SLIDE 7

So what are artifically-intelligent agents? To grasp this concept, here we have a video of what is considered the first intellligent (not artificial) agent that we are aware of, which is known as a slime mold and is a large amoeba-like cell that is able to expand and merge with other cells of that type in order to search for food. Once the food has been found, it modifies its shape in order to spread the food throughout all the organism in an efficient way. In this experiment, the researchers have placed different slime molds inside a maze, and then put two food sources at different points of the maze. After and expansion phase, the slime mold finds the food source and communicate with the rest of the organism. Finally, in the contraction phase, it optimizes the shape in order to bring the food throughout the entire organism, and such solution is given by solving the maze. As we can see, it finds a pretty efficient solution for the maze.    ---> END WITH PICTURE

SLIDE 8

Artificial intelligence is about mimicking and exploiting such properties of natural systems in order to tackle some problem that we humans want to deal with.

For instance, reinforcement learning is inspired in wether the food was found or not, and the agent optimizes its actions according to the rewards it enjoys. Importantly, only the reward can be used for the optimization, and thus a model of the environment is not strictly necessary, meaning that the agent learns solely by the reward value.

Similarly, we can use the slime-mold (or algorithms inspired in slime-mold behaviour) for optimization problems, where the model and rules of the problem are shown to the agent, but the solutions are unknown even for us. In this example, researchers have placed food in a scaled map of cities around Tokio, and after the expansion + contraction phases, the slime-mold structures in a shape strikingly similar to the japanese rail system network.

Finally, we might use machine-learning methods to discriminate between different objects - or even people -, and track them. These algorithms have their roots in statistical inference methods, and are a way to process data that is observed in real-time.

SLIDE 9
So, what I do in my thesis is to study how different machine-learning agents (which might or might not be very sophisticated in practice) can help us to make decisions on the three different problems regarding quantum information processing and technological applications.

The frameworks are interconnected to each other by the awareness degree that the agent posses of the task at hand. This means how much information the agent has aboutthe problem is asked to solve.

In the long-distance setting, we will give basically no information to the agent, and asked to calibrate the measurement using only a binary reward signal, ignoring the intensity of the signals, or outcome probabilities. Thus, we will say that the agent learns in the darkness

In the circuit design problem, the agent will be equipped with information about the circuit (it will know how the circuit looks), and will also be given a circuit optimization toolkit. However, the structure of the solution and a model that tells whether a circuit is good or not is even unavailable to us, and thus the agent is semi-agnostic. Thus, we will say that the agent learns in the twilight.

In the data processing for continuously-monitored systems, the agent will have full knowledge of the signals' probability distributions, and it will be asked to deal with statistical inference problems, namely with parameter discrimination and estimation. Thus, we will say that the agent learns in the daylight.

SLIDE 10
So here it is the outline of my dissertation. Each of the next Sections corresponds to a Chapter of my PhD thesis, and the Chapters are interconnected to each other by the awareness degree, they can also be considered independently, and this is what we will do now. In this regard, by the end of each chapter I will potentially become very technical, however if someone gets lost, you can recap in the following section.

SLIDE 11
In short, this Chapter is based on our works on reinforcement learning and coherent state discrimination.

This is a paradigmatic problem in quantum information processing, which consists in distinguishing between two different coherent states, whose overlap is different from zero. Here, we have in mind a situation where the coherent state is sent from a satellite, and while the original intensity might be high, the intensity of the coherent state that arrives to ground-earth is extremely weak, almost vacuum. While light does not interact much with the surroundings, and it travels quite fast, the dominant source of noise are losses, formally known as lossy channels.

Thus, it is of utmost importance to perform, on ground earth, a quantum measurement that has a success probability as high as possible so to best discriminate between the states. In particular we care about experimental implementations using currently-available technology in optical labs.

For a given measurement apparatus, we tackle the problem of model-free calibrating it, by using RL techniques. Due to its agnostic nature, the method exhibits a noise-robustness feature in realistic long-distance quantum communication scenarios that we have simulated in our computers.

SLIDE 12
Thus, we consider the problem of minimum-error discrimination between two coherent states whose intensity is \alpha, but their phases are opposite. In particular, Alice encodes the value of a classical bit of information in such a phase, and Bob performs a two-outcome POVM M, and according to the measurement outcome and its decision rule, he performs a guess.

SLIDE 13
How good Bob's strategy is - which consists in choosing the POVM M and a guessing rule g- is quatified by the success probability, which is averaged out over all possible measurement outcomes of M.

A fundamental result in quantum information is that the success probability when discriinating two arbitrary states \rho_0 and \rho_1 is upperbounded, for any strategy consisting on a POVM + guessing rule, by the Helstrom bound, and the optimal measurement that saturates the bound is given by a projection over positive and negative part of the diffrence between the candidate states.

This projection is, for the coherent-state discrimination problem we are dealing with, translated into a projection over cat-like states, which are superpositions of coherent states. As we will see, for this particular case, there is a way to realize such projection using lineal-optics + bucket photon-detections + feedback, known as the Dolinar receiver.

SLIDE 14
However, before jumping to discuss the Dolinar receiver, let us discuss how simple operations can do. Here, we associate simple operations to Gaussian transformations, which are associated with hamiltonians which are quadratic in the creator/anhilation operators. Their action on Gaussian states (here the vacuum) are linear in phase space.

For us it will be relevant to highlight the displacement, which maps coherent states to coherent states, and changes their amplitude.

Moreover, Beam Splitters can be used to mix two modes, and they also belong to the class of Gaussian operators.

Finally, when it comes to quantum measurements, we have Gaussian measurements, which acting on a Gaussian state gives rise to a Gaussian probability function for the outcome. For the problem of discriminating two coherent-states, the optimal Gaussian measurement can be proven to be the homodyne.

SLIDE 16
Thus, we can readily compute the success probability of the homodyne receiver, and compare it with the Helstrom bound, for different signal's intensities. As we can see, as the intensity approaches to zero, the states become closer and closer to the vacuum, and thus it is more difficult to discriminate between them. On the contrary, if the intensity is very high, the success probability approaches unity.

However, we see that there is still an important gap between homodyne and Helstrom

SLIDE 17
This gap can partially be closed by considering a non-gaussian measurement by the end of the receiver, given by bucket photodetectors, which measures either 0 or 1 or more photons.

In turn, the Kennedy receiver performs a displacement of the incoming states by a value \beta, and then measures with an on/off photodetector.

Here, let us note that the success probability will depend on the value \beta that the Kennedy recevier performs

SLIDE 18
If we optimize such success probability over \beta we get an advantage over the homodyne receiver.

SLIDE 19
However, as I mentioned earlier, there exists a way to implement the optimal measurement (i.e. projecting over cat-like states). This is given by the Dolinar receiver, and consists in sequentially splitting the incoming state by a BS and performing local Kennedy measurements on the reflected part. The measurement outcome will condition the value of the displacement that is done on the transmitted part of the state.

Here, we show the results for a 2-Dolinar receiver, which consists on two consecutive Kennedy-like receivers. As we can see, the performance is improved. however, let us note that for a given \alpha, the optimal values of the displacements need to be found. In this example we have three displacements: the first displacement, the displacement done if the first outcome was 0 and the displacement done if the first outcome was 1, conditioned as well on the value of the previous displacement. What we see is the optimized success probability for this 2-Dolinar receiver.

SLIDE 20
The optimization of the receiver in terms of the displacement trees is a very challenging one, and can be casted in terms of dynammic programming. As we see, as L increases, the success probability becomes closer and closer to the Helstrom bound.

SLIDE 21.
While there have been experimental proof of concepts in the past, noise in the detectors ultimate limits the reachability of the Helstrom bound, even after optimizing the conditional displacements tree for the specific setting.

SLIDE 22
This motivated us to propose a radically different approach, where we cast the calibration of a Dolinar-like receiver in a completely agnostic way.

Instead of optimizing the success probability, we give an uncalibrated Dolinar receiver to an RL agent and ask it to use it optimally.

Here, the RL agent needs to find the best receiver configuration (i.e. the whole conditional displacements tree) by performing the real discrimination experiment. That is, for each experiment the agent needs to make a guess for the phase of the coherent state, and we give him a reward of 0 or 1 if the guess is correct or not.

Importantly, the agent is unaware of the setting, we give him no model for the outcome probabilities, nor the intensity of the incoming signals, nor what the displacements are doing. For any other purposes, the agent only press buttons according to the outcomes it observes.

SLIDE 23
This buttons give the values of the displacements to be done at each layer of the receiver, and at each intermmediate step the agent can only observe the measurement outcome, which is used to decide the next conditional displacement value.

The mechanism behind the model-free learning works essentially by keeping track and updating an estimate of the expected reward that a given displacement leads condition on the outcomes and displacements previously done.

Since such value is unavailable to the agent because it does not have the proper knowledge of outcome probabilities nor signal intensities, it needs to estimate it by trial and error.

However, the agent is asked to use the receiver as best as it can from the very first experiment, and thus it appears a trade-off between exploring new displacements and exploiting the displacements that the agent thinks that are the optimal ones.

SLIDE 24
How this trade-off is balanced is given by the agent's policy. On the one hand we have the traditional \epsilon-greedy policy, where with probability \epsilon it behaves randomly when choosing a displacement, and with probability 1-\epsilon it selects the displacement he thinks is the best one.

Then, in our work we have designed more sophisticated policies, where we got inspiration from bandit theories, and considered UCB and Thompson-Sampling ones, which are the green and blue curves.

As we see, each policy balances the trade-off differntly.

In the plot of above we show our figure of merit, which is the empirical success rate obtained up to experiment t. We see that all agents are able to reach an empirical success rate that ahieves the optimal success probabilty of the receiver under consideration, which indicates that not only the agent has found the optimal configuration of the receiver, but also that is has been implementing it for quite a while.

In the plot of below, and for benchmarking purposes, we show another possible figure of merit, which considers having access to the model. Here, we see the success proability associated to the favorite configuration the agent has at episode t. However, let us remark that this configuration might not be implemented at each time-step by the agent, since he is exploring potentially better ones.


SLIDE 25
The model-free feature of the reinforcement learning agent naturally adapts to a variety of scenarios. Here, we have tested different situations, for example what happens if we include fake counts in the detectors, a case known as dark counts, and we see that for a wide range of dark count probability it is still successful in performing (and not only finding) the optimal configuration.

SLIDE 26
We have also tested a quite unfair situation, where we flip the phase of the coherent state before it arrives to the receiver, and similarly to the dark count case the agent is also able to adapt to this situation.

SLIDE 27
Moreover, we have studied a realistic scenario, where the signals are trasnmitted through a variable-loss lossy channel. For instance, a cloud might alter the transmissivity of the atmosphere, and such cloud might appear with some probability. We also see that for this situation the agent is able to adapt.

SLIDE 28
So as a recap, this section was about coherent-state discrimination.

The optimal measurement can be implemented by the Dolinar recevier, however noise hinders a succesful implementation.

Here we proposed a model-free method that actively use the receiver in order to calibrate it. Importantly, we measure its performance by the empirical success dsicrimination rate, and we see that not only it reaches the optimal configuration but also that it performs it.

We showcase out model-free method in a wide variety of noise models, and show that is ready for an experimental implementation.

SLIDE 29
Specifically our contributions to the fields are the following ones...

Some issues we need to take into acccount and haven't so far...

SLIDE 30
some next steps ---> connection with finding new receivers.

SLIDE 31
take a breath :-)

So now  we will turn to the learning in the twilight chapter

VANSSSS
SLIDE 32
In short, this Section is based in a work we have done in collaboration with the quantum computing research group at Los Alamos,

and it consists on a method that enhance variational quantum algorithms, by means of improving the way that quantum circuits are considered.

In particular, we prpose an algorithm for quantum circuit discovery, which adapts the quantum circuti layout to the specific hardware constraints and thus exhibits a robusteness against noise when testing it in noisy scenarios.

SLIDE 33
Since the last few years, experimentalists are able to build up NISQ computers, which are small and nosiy versions of a quantum computer, with up to a hundred qubits.

While we cannot build arbitrarly large circuits due to noise accumulation, we can do something, which is preparing a quantum state and evolve it for a sufficiently large amount of time, which is very impressive.

This devices can be modelled as follows, we have some quantum gates that we can implement, for instance arbitrary rotations around X and Z values (here I denote it by X,Z but they are rotations), and we can build up a quantum circuit by placing such gates as we wish. In practice there are connectivities constraints, but we will not considered this here.

Once the circuit is built, and acting on a fiducial state, the circuit prepares some state \psi, and we can readily calculate some statistic related, for example, to a Hamiltonian. However, let us note that we have a huge freedom in making use of this apparatus, which is choosing the values of the parameters. Similarly to the way that our RL agent was initializing its learning, we begin here from an unbiased choice, that means, choosing the parameters of the circuit at random.

After running the circuit with this parameters for many times, we gather enough statistics and are confident that the energy associated to the state we are preparing (and our hamiltonian) is some value.

However, we would like now, similar to the RL agent, to use this machine for something. A paradigmatic example is to use the circuit in such a way that \psi corresponds to the ground-state of our hamiltonian. However, we do not have access to the entire energy landscape (it might be very complicated, for instance this image, where we have only estimated one point out, for instance this one), and thus an obvious question appears: how do we change the parameters so to minimize the energy?

SLIDE 34
A method that has gained much popularity is variational quantum algorithms, where the quantum device is only used to estimate cost function value and then a classical optimization algorithm is in charge of modifying circuit paramters.

Thus, we can identify three main ingredients for VQAs: the quantum circuit, which we will can ANSATZ

the cost function (for instance, the expected value of our Hamiltonian)

and an optimization procedure. Regarding this, one would think that estimating the cost function gradient (to be used in the optimization) can potentially be very demanding (for instance, by the usage of finite-difference methods). However, there is a trick, which is known as gradient-shift rules

SLIDE 35
In a nutshell, gradient-shift rules allows us to use the very same circuit under consideration in order to estimate the derivative of a given paramter, say \alpha, by just evaluating the cost at a shifted set of parameters. This is nice, because we can not only use the quantum device to estimate the cost function value, but also we can use it to estimate its gradient. Otherwise we would actually be in trouble, since simulating this is more often classically forbidden.

Thus, the goal of VQAs is to find the global minima of our cost-function, by sequentially estimating the cost-function value and its gradient, and modifying the parametrs by a classical algorithm (for instance, gradient-descent).

SLIDE 36
However, people quickly realized that this approach of random initialization of sufficiently random circuits ussually fails, and the so-called Barren Plateaus appears.

In short, when a circuit exhibits a Barren Plateau, estimating a cost-minimizing direction is exponentially hard, in terms of the number of measurements one needs to perform.

This is due because for sufficiently random circuits, the probability of picking a set of parameters \theta whose cost-gradient is larger than zero is exponentially small. Thus, we can think of the parameter landscape of a circuit that presents a Barren Plateau as a very challenging one, and hard to navigate. On the one hand exhibiting a flat landsacpe, and on the other hand exhibiting this narrow gorge, where the global minima lies. Essentially, under the preseence of a barren plateau, any parameter optimization method will fail on average.

Much has been studied about Barren plateaus, since this is a no-go result for NISQ tehcnology. In particular, it has been shown that the presence of a barren plateau can be associated to how expressible (or how random) a given circuit is, when varying the set of paramters.

On the other hand, it has been shown that there exists another type of Barren Plateau, which is induced by noise. Here, the presence of noise in circuit's gates flattens the entire parameter landscape.

SLIDE 38
Thus, having all this problems, it is very important to develop new optimization methods, that are able to exploit any component of NISQ devices. In particular, here we will focus on going beyond the paradigm of having a fixed circuits whose parameters are optimized over, and present an algorithm which also optimizes the structure of the circuit.

Contrary to the RL case, here our algorithm is semi-agnostic because the agent does observe the circuit and the cost-function value at each time-step. However, it is still not model-aware, since we cannot provide it with the full parameter landscape, since even us ignore it.

SLIDE 39
Thus, VAns works in a nested loop way, where the continuous parameters are optimized, and then the structure.

This is an sketch of a VANs training experiment, where again Z(X) are parametrized single-qubit rotations.

We begin with a very shallow circuit, chosen before-hand, and then we optimize its parameters with some classical method (for instance gradient-descent).

Then, VAns grows the circuit by inserting some gates in a random fashion, and re-optimize the entire set of parameters.

Afterwards, it applies a set of simplification rules, and decides whether to accept or reject the initial modification based on some decision criteria.

This loop is continued until some convergence criteria is reached.

SLIDE 40
Specifically, VANs grows the circuit by inserting a set of gates that compiles to the identiy, and in practice this is useful since the cost should in principle not increase, and the transision is smooth, which is important for the continuous optimization.

Moreover, VANs simplifies the circuit by using some equivalence rules, for example compiler more than 3 consecutive rotations into Euler rotations, or move all the CNOTs to the left when possible. Also, it scans the circuit to detect the presence of unnecesary gates in the circuit, and if detected, it removes them.

SLIDE 41
So, we have implemented VANs for a wide range of tasks in what people call quantum machine learning. Now I will present to you some results regarding the usage of VANs for variational eigensolver task, which consists in preparing the ground state of a given hamiltonian.

SLIDE 42
We will focus on the transverse field ising model, and as we can see VANs is able to find ground-state preparing circuits for a wide range of transervse fields

SLIDE 43
Importantly, we here show VANs learning curves, and we see that our method is able to make better use of the quantum resources (namely the number of gates) as compared with fixed-structured ones, namely Hardware Efficient Ansatz.

Here, we compare the energy of the final circuit found by VANs, with that of an HEA circuit having the same number of parameters & CNOTS (2-HEA) than VANs circuit does.

Moreover, we have compared this with increasing the number of layers in HEA and we see that VANs readily surpasses this limit.

SLIDE 44
Finally, we have invented a noise model for benchmarking pursposes, which is parameterized by a single parameter \lambda, and we studied a wide variety of lambda regimes. Here, we compare VQE task for 8-qubit TFIM as \lambda increases, with different HEAs, and we see that VANs succesfully adapts the circuit layout to the noise strength at hand.

SLIDE 45
To sum up, in this Section we have tackled the problem of VQA, and in particular the optimization of quantum circuit structure

we introduced VANs method, and numerically shown that is able to outperform fixed-structure ansatzses.

Vans works by sequentially optimizing, increasing  and compressing the quantum circuit, and its decisions are only based on the cost-function value.

SLIDE 46
In this regard, our contributions to the field are that VANs works for general cost functions, it adapts the quantum circuit layout to the situation at hand by using specific circuit compression rules.


Let me point out that, as in every project, VANs has some weak points and issues. For example, it inserts gates at random positions, instead of using potentially previous knowledge from a previous "database" of quantum circuits.

SLIDE  47

Some possible extensions and future works that i can figure out are
on the one hand using VANs for complementing our reinforcement learning method that learns in the darkness, and thus discover new continuous-variable quantum receivers.

On the other hand, there are many enhancements that we could think for VANs, and it is an open question whether we can improve it by means of reinforcement learning tehcniques.


SLIDE 48
