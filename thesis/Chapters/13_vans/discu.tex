In this Chapter, we have introduced the VAns algorithm, a semi-agnostic method for building variable-structure parametrized quantum circuits.

At each iteration of the optimization, VAns stochastically grows the circuit to explore the architecture hyperspace. Crucially, VAns also compresses and simplifies the circuit by removing redundant and unimportant gates. This is a key aspect of our method, as it differentiates VAns from other variable ansatz approaches and allows us to produce shallow circuits, which can potentially mitigate the effect of noise.

To showcase the performance of VAns, we simulated our algorithm for several paradigmatic problems in the so-called quantum machine learning framework. Namely, we implemented VAns to find ground states of condensed matter systems and molecular Hamiltonians, for a quantum autoencoder problem and for 10-qubit QFT compilation. In all cases, VAns was able to satisfactory create circuits that optimize the cost. Moreover, due to VAns' specific circit-compression rules, these optimal circuits contain a small number of trainable parameters and entangling gates. Here we also compared the result of VAns with those obtained by using a Hardware Efficient Ansatz with either the same number of entangling gates or the same number of parameters: in all cases we found that VAns could achieve the best performance. This point is crucial for the success of VAns in the presence of noisy channels, as it automatically adapts the circuit layout to the situation at hand (\textit{e.g.} noise strength). For instance, under the $\lambda$-model (which is the noise model we have proposed and implemented), VAns notably outperforms HEA under ground-state preparation tasks.

While we provided the basic elements and structure of VAns (\textit{i.e.}, the gate \texttt{Insertion} and gate \texttt{Simplification}  rules), these should be considered as blueprints for variable ansatzes that can be adapted and tailored to more specific applications. For instance, the gates that VAns inserts can preserve a specific symmetry in the problem. Moreover, one can cast the VAns architecture optimization (\textit{e.g.}, removing unimportant gates) in more advanced learning frameworks. Examples of such frameworks include supervised learning~\cite{supercomi} or reinforced learning schemes~\cite{foselgoogleRL,Moro2021,HerreraMarti2022policygradient}, which could potentially be employed to detect which gates are the best candidates for being removed.

We expect VAns to be especially useful for abstract applications, such as linear systems~\cite{bravo2020variational,huang2019near,xu2019variational}, factoring~\cite{anschuetz2019variational}, compiling~\cite{khatri2019quantum,sharma2019noise}, metrology~\cite{beckey2020variational,koczor2020variational}, and data science~\cite{larose2019variational,cerezo2020variational,biamonte2017quantum,schuld2014quest,abbas2020power,verdon2019quantum}, where physically motivated ansatzes are not readily available. In addition, VAns will likely find use even for physical applications such as finding grounds states of molecular and condensed matter systems, as it provides an alternative to physically motivated ansatzes for mitigating the impact of noise, as shown in our noisy simulations. This is particularly promising since we have seen that VAns readily adapts the ansatz to the noise situation at hand.

Let us now discuss how VAns is expected to deal with barren pleateaus, which currently constitute one of the major barriers for the success of VQA frameworks.

\subsection{Mitigating the effect of barren plateaus}
% Let us now discuss why VAns is expected to mitigate the impact of barren plateaus.
First, consider the type of BPs that are caused by the circuit approaching an approximate 2-design~\cite{mcclean2018barren}. Approximating a 2-design requires a circuit that both has a significant number of parameters and also has a significant depth~\cite{brandao2016local,dankert2009exact,harrow2009random,harrow2018approximate,haferkamp2022randomquantum}. Hence, reducing either the number of parameters or the circuit depth can combat the appearence of barren plateaus. VAns attempts to reduce both the number of parameters and the depth and consequently attempts to avoid approximating a $t$-design.

Second, consider the BPs that are caused by hardware noise~\cite{wang2020noise}. For such barren plateaus, it was shown that the circuit depth is the key parameter, as the gradient vanishes exponentially with the depth. As VAns actively attempts to reduce the number of CNOTs, it also reduces the circuit depth. Hence VAns will mitigate the effect of noise-induced barren plateaus by keeping the depth shallow during the optimization. As we have seen in our noisy simulations in Sec.~\ref{ssec:vans_results_noise}, VAns automatically adjusts the circuit layout in such a way that the cost function reaches a minima, which translates to short-depth circuits in noisy scenarios.

\subsection{Future directions}

\subsubsection{BP-aware implementation}
While in the previous subsection we have presented general arguments as to why VAns can improve trainability, here we instead present a practical method that combines VAns with the recent techniques of Ref.~\cite{sack2022avoiding} for mitigating barren plateaus using classical shadows.

As discussed in Sec.~\ref{ssec:1_nisq_barrenplateaus}, it is known that the presence of barren plateaus is intrinsically related to the entanglement generated in the circuit~\cite{sharma2020trainability,patti2020entanglement,marrero2020entanglement}. That is, circuits generating large amounts of entanglement are prone to barren plateaus. With this remark in mind, the authors in~\cite{sack2022avoiding} propose to detect the onset of a barren plateau by monitoring, at each iteration, the entanglement of the resulting state. This can be achieved by computing, via classical shadows~\cite{huang2020predicting}, the second R\'enyi entanglement entropy $S_2(\rho_R)=-\log(\tr{\rho_R^2)}$, where
\equ{\rho_R=\text{Tr}_{\overline{R}}\left[U(\kvec,\thv)\rho_i U^\dagger (\kvec,\thv)\right]}
denotes a reduced state on a subset of $R$ qubits. As such, if $S_2(\rho_R)$ approaches the maximal possible entanglement of the $S$ qubits, given by the so-called Page value $S^{\text{page}}\sim k\log(2)-\frac{1}{2^{n-2k+1}}$, one knows that the optimization is leading to a region of high entanglement, and thus of barren plateaus.

The key proposal in~\cite{sack2022avoiding} is to tune the optimizer (\textit{e.g.}, by controlling the gradient step) so that regions of large entropies are avoided. This technique is shown to work well with an identity block initialization~\cite{grant2019initialization}, whereby the parameters in the trainable unitary are chosen such that $U(\kvec,\thv)=\id$
at the start of the algorithm. Note that, in principle, this is still a fixed-ansatz method, as some circuit structure has to be fixed beforehand, and as no gates are ever removed. Hence, the methods in Ref.~\cite{sack2022avoiding} can be readily combined with VAns to variationally explore the architecture hyperspace while keeping track of the reduced state entropy. In practice, this means that one can modify the VAns update rule to allow for steps that do not significantly increase entropy, while favouring steps that keep the entropy constant, or even that reduce it (\textit{e.g.} by removing gates during the \texttt{Simplification} modules).

\subsubsection{Reinforcement-learning}

Recaping the formalism of RL introduced in the previous Chapter, we might be tempted to define state-action value functions as done in Chapter~\ref{chapter:RLCOH}, where the problem was to find quantum receiver configurations. Nonetheless, we are here dealing with a task of higher complexity, as illustrated when casting it in terms of reinforcement learning. For instance, we can define $\mathcal{C}(\thv)$ to be the state $s$ of the circuit (\textit{e.g.} a classical description of circuit's layout and parameters value $\thv$), and the actions $aÂ \in \mathcal{A}$ consisting on placing a parametrized gate $G_x(\alpha) \in \mathcal{A}$, at the $x$-th position in the circuit, where $\mathcal{A}$ is a dictionary of available quantum gates that can be used to grow the circuit. Moreover, we can define the reward to be the global minima of the cost-function associated to state $s$ (assuming the classical optimization algorithm is capable of finding it). From here, we could opt to consider an infinite-horizon scheme, where the environment dynamics $\tau$
becomes a deterministic function of $s$ and $a$\footnote{We could slightly complexify the model, for instance by including circuit compression rules carried out after each gate-insertion}. However, inferring the state-action value function constitutes an extremely hard task, since one should consider any possible circuit layout reachable from $s'$ on. Moreover, the presence of quantum correlations makes the encoding of circuit's state a highly non-trivial task; here, we would need an encoding that allows to process the circuit by \textit{e.g.} a neural network (or more sophiscitated RL agents).

Nevertheless, we could think of an hybrid appraoch, under which a subset of candidate quantum circuits is found by VAns, and an RL-agent is rewarded by filtering the important features of cost-minimizing circuits, and repeating such approach iteratively, which would fall under the umbrella of batched reinforcement learning.

\subsubsection{CV systems, receivers and beyond}
The VAns algorithm can also be casted in discovering useful continuous-variable quantum neural network structues~\cite{cvnetworks}. In this regard, we shall not restrict our attention to quantum-computing problems, and we note that VAns could also be applied to similar problems than those dealt during Chapter~\ref{chapter:RLCOH}. In turn, very little is known about the structure of near-optimal and implementable quantum receivers (particularly if the states form an $M$-ary set of coherent-states, with $M\geq3$). Here, the cost-function to be optimized is the error probability, $\kvec$ would be the POVM struture, in terms of symplectic transformations (given by phase-shifts, beam-spliters, etc.) and active transformations (squeezing, displacements) parametrized by $\thv$. In this regard, similar problems could be considered, such as channel-discrimination and parameter estimation (where the cost-function will be linked to the fisher information).


\subsection{Code}
Most of the code and simulations supporting this Chapter can be found in the repos~\cite{Vansgb0} and ~\cite{Vansgb}. As a bonus, a tutorial used for introducing quantum variational methods to undergraduate quantum physics students can be found in~\cite{castellers}
